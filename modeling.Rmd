---
title: "Modeling_Katrina"
author: "Katrina Truebebach"
date: "March 18, 2019"
output: pdf_document
---

```{r}
rm(list = ls())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(stringr)
library(lubridate)
library(modelr)
library(tis)
```

## Load cleaned data

```{r load}
load(file = '~/DS5110/data/proj_cleaned_dta.RData')
```

# Fit Model with Genre Variables vs Real Revenue

## Step Wise Selection
End model includes (in order of steps): 'Adventure', 'Action', 'Family', 'Mystery', 'Documentary', 'Drama', 'History', 'Romance'  
  
Dependent variable is log(real_gross). Makes model look better _and_ a lot of the relationships with other variables are more linear with log, so we will need to use this as y variable in the main model.  
    
This model selection by and large makes sense. All included variables are significant at some level.  
However, according to Qiang's graphs in EDA, some of the included genres do not make a real difference to real_gross. Especially History. Also, some genres that look like they would make a signficant difference are not included. For example, Animation.
  
Thoughts:  
  
* There are a few genres that define almost all of the movies (For example, almost 80% of the movies are either Adventure, Action, Romance, or Drama). Thus, the relationship between revenue and some genres can be explained by other generes. For example, 93 out of 99 Animation movies are also Family. So Animation's effect on revenue may already by captured by Family, which is included in the model.
* On the flip side, History is included even though it seems to have a negligable effect on revenue based on the EDA bar graphs. I don't have a great explanation for this other than it was close to the cutoff RMSE for being included. 53 out of 55 History movies are also Drama. So unclear why included.  
   
Also, the residuals are debatably random vs included and excluded variables in model (not sure if these are not-random enough to matter -- see graphs).  
More concerning is the fact that the residuals themselves are not Normal. See QQ-Plot (close-ish...)

```{r exmaples, eval = F}
train %>% filter(Animation == 1, Family == 1) %>% count() # 93
train %>% filter(Animation == 1) %>% count() # 101

train %>% filter(History == 1) %>% count() # 55
train %>% filter(History == 1, Drama == 1) %>% count() # 53

```

Which genres should we be using?  
Note: not using the step() function because can't fit and find RMSE on different datasets (train, valid)


```{r step_wise_fn}
# version of train set with just genre columns to loop through 
train_genre_only <- train %>% select(Action, Adventure, Animation, Biography, Comedy, Crime, Documentary,
                Drama, Family, Fantasy, History, Horror, Music, Musical, Mystery,
                Romance, SciFi, Sport, Thriller, War, Western)

# calculate log(real_gross)
train <- train %>% mutate(real_gross_log = log10(real_gross))
valid <- valid %>% mutate(real_gross_log = log10(real_gross))

# function to automate each step of stepwise variable selection
# df_vars is the dataset with only the relevant variables 
# var_lst is the list of variables that are in the base model
# formula is the formula with those variables besides the y variable
step_wise_step <- function(df_vars, var_lst = NULL, formula = NULL) {
  # if first step
  if (length(var_lst) == 0) {
    # rmse with each variable against real_gross
    rmse_vars <- sapply(names(df_vars), function(var) {
      # rmse of model
      rmse(lm(as.formula(str_c('real_gross_log ~', var)), data = train), data = valid)
    })
  # if > first step: exclude variables from var_lst from data and include in model formula
  } else {
      rmse_vars <- sapply(names(df_vars %>% select(-var_lst)), function(var) {
      # rmse of model
      rmse(lm(as.formula(str_c('real_gross_log ~', formula, ' + ', var)), 
              data = train), data = valid)
      })
  }
  # return the name and value of the genre that resulted in the lowest RMSE 
  return(rmse_vars[which.min(rmse_vars)])
}

# function to loop through each step wise loop
# adding optional starting vars and formula in case want to build off of an existing formula 
step_wise_loop <- function(df_vars, starting_vars = NULL, starting_formula = NULL) {
  # list to store min RMSE from each step in 
  rmse_lst <- c()

    # first step: no genre_lst or formula (default values NULL)
  min_rmse_var <- step_wise_step(df = df_vars, var_lst = starting_vars, formula = starting_formula)
  print(min_rmse_var)

    # add to list of genres, formula, and min RMSE list
  var_lst <- c(starting_vars, names(min_rmse_var))
  formula <- str_c(starting_formula, '+', names(min_rmse_var))
  rmse_lst <- c(rmse_lst, min(min_rmse_var))
  
  # if have starting variables, take those out of the number we are iterating through
  if (!is.null(starting_vars)) {
    df_vars_seq <- df_vars %>% select(-starting_vars)
  } else {
    df_vars_seq <- df_vars
  }
  # loop through until have considered every variable 
  for (i in seq(1:(ncol(df_vars_seq)-1))) {
    print(i)
    # step
    min_rmse_var <- step_wise_step(df = df_vars, var_lst = var_lst, formula = formula)
    print(min_rmse_var)
    
    # add to lists
    var_lst <- c(var_lst, names(min_rmse_var))
    formula <- str_c(formula, ' + ', names(min_rmse_var))
    rmse_lst <- c(rmse_lst, min(min_rmse_var))
  }
  return(rmse_lst)
}

```

```{r step_wise}
# step wise implement
# return list of all min RMSE from each step -> graph
rmse_lst <- step_wise_loop(df = train_genre_only)
```

### Graph RMSE vs number of variables: how many to include?  
Specify 'final' model  

```{r rmse_gr}
# graph RMSE at each step 
fit_rmse <- tibble(nvar = 1:length(rmse_lst), 
                   rmse = rmse_lst)
ggplot(fit_rmse) + geom_line(aes(x = nvar, y = rmse))+ 
  scale_x_continuous(breaks = seq(1, length(rmse_lst), by = 1))
# after var 8, decreases too small or increase 

# model based off of step wise 
# HOWEVER some of these variables are insignificant 
  # (see pvalues and graphs from Qiang's EDA where barely any difference in revenue from genre)
mod_genre <- lm(real_gross_log ~ Adventure + Action + Family + Mystery + 
            Documentary + Drama + History + Romance, 
          data = train)

summary(mod_genre)
rmse(mod_genre, data = valid)

# list of these variables for future use
genre_xvar <- c('Adventure', 'Action', 'Family', 'Mystery',
                'Documentary', 'Drama', 'History', 'Romance')
```

### Graph variables in and out of model against residuals. Most are fairly evenly distributed around residual. Worst is probably Western.

```{r genre_resid}
# graph residuals against each variable included in the model
# most look random except Adventure
train_resid <- train %>% 
  add_residuals(mod_genre, 'lresid') 

lapply(genre_xvar, function(var) {
  train_resid %>% 
    ggplot() + 
    geom_boxplot(aes_string(var, y = 'lresid'))
})

# graph residuals against each genre not included in the model 
# several are questionable if random. Especially Animation.
lapply(names(train_genre_only %>% select(-genre_xvar)), function(var) {
  train_resid %>% 
    ggplot() + 
    geom_boxplot(aes_string(var, y = 'lresid'))
})
```

### Plot QQ plot for residuals. Not normally distributed, but close-ish.

```{r qq}
# residuals themselves are NOT normally distributed 
# qq plot 
train_resid %>% ggplot() + 
  geom_qq(aes(sample = lresid))

```


### Plot Predictions
Plot prediction for mean real revenue against each genre included in the model.  Looks pretty accurate!  

```{r predictions}
train_pred <- train %>%
  add_predictions(mod_genre, 'lpred') %>%
  mutate(pred = exp(lpred)) 

lapply(genre_xvar, function(var) {
  train_pred %>% 
    ggplot(aes_string(x = var)) + 
    geom_boxplot(aes(y = real_gross)) +
    geom_point(data = train_pred %>% group_by(!!rlang::sym(var)) %>% summarize(mean = mean(pred)),
               aes(y = mean), color = 'red', size = 2)
})
```

## Glmnet: sparse 
Quickly try this new method from class instead of stepwise. The sparse version does give us a lot of the same variables as stepwise. Good sign!  
Can't do statistical tests, so not useful for analysis, but can use to aid justification.

```{r sparse}
library(glmnet)
 
# matrix of x and y variables
x <- as.matrix(train_genre_only %>% mutate_all(funs(as.numeric(as.character(.)))))
y <- as.matrix(train$real_gross_log)

# glmnet process form class 
mod_sparse <- glmnet(x, y, family = 'gaussian')
plot(mod_sparse, xvar = 'lambda', label = TRUE)
mod_sparse <- cv.glmnet(x, y)
plot(mod_sparse)
coef(mod_sparse, s = 'lambda.min') # use min lambda
coef(mod_sparse, s = 'lambda.1se') # use most sparse
```


# Fit model with other variables 

## Plot residuals of other variables based on the genre model. 
All of these plots indicate a relationship that is not fully represented in the model yet and thus all are valid candidates for including in the model (also given their relatively linear relationships)
   
For example, movies with lower budgets make less revenue than predicted by the genres in the model (negative residual) and movies with higher budgets make more revenue than predicted by genre (positive residual). Cast facebook likes, director facebook likes, and IMDB score follow a similar pattern.  
Many years have revenue either higher or lower than that predicted by genre.  

Content rating has more of a random relationship with the residual. Perhaps this is because genres and content ratings have some correlation (i.e. Family movies tend to be G or PG while Horror tend to be R) and thus this relationship may have already been captured.  
There is some indication that R movies may make less revenue than predicted and PG-13 movies make more revenue than predicted. 

```{r other_resid}
# get log versions of variables since residuals are log: same scale 
train_resid <- train_resid %>%
  mutate_at(vars('real_budget', 'director_facebook_likes', 'cast_total_facebook_likes', 
         'imdb_score'), funs(log = log10(.)))

# graph each against log residual: continuous
lapply(c('real_budget', 'director_facebook_likes', 'cast_total_facebook_likes', 
         'imdb_score'), function(var) {
  print(var)
  train_resid %>% 
    ggplot() + 
    geom_point(aes_string(str_c(var, '_log'), y = 'lresid'))
})

# categorical 
# can't log categorical variables 
lapply(c('content_rating', 'year'), function(var) {
  train_resid %>%
    filter(!is.na(!!rlang::sym(var))) %>%
    ggplot() + 
    geom_boxplot(aes_string(var, 'lresid')) + 
    coord_flip()
})
```

## Stepwise: Genre as Base

Try stepwise selection with these other variables given that none had fully random relationships with the residual from the genre model. Use the fitted genre model as a base.  
  
For factor variables (content_rating, total_oscars) use normal versions of variables.  
For facebook likes, use log versions as those were more linear with log(real_gross).  
For budget and IMDB score, I think log versions are better, but try the non-log versions too. Both had some linearity.  
For year, use normal version.  
```{r other_step}
# create log versions of continuous variables
# also turn -Inf from log(0) to NA 
train <- train %>% 
  mutate_at(vars('real_budget', 'director_facebook_likes', 'cast_total_facebook_likes', 
         'imdb_score'), funs(log = log10(.))) %>%
  mutate_at(vars(contains('log')), funs(ifelse(is.infinite(.), NA, .)))
valid <- valid %>% 
  mutate_at(vars('real_budget', 'director_facebook_likes', 'cast_total_facebook_likes', 
         'imdb_score'), funs(log = log10(.))) %>%
  mutate_at(vars(contains('log')), funs(ifelse(is.infinite(.), NA, .)))

# starting formula: genre
starting_formula = 'Adventure + Action + Family + Mystery + Documentary + Drama + History + Romance'

# stepwise starting with genre 
# need to drop years before 1980: too sparse
  # most of those years have 1 or 0 observations. If including year in the model, we aren't getting any information from those
  # and it makes it impossible to fit on both train and valid because the levels of the factor are different
train <- train %>% filter(as.integer(as.character(year)) >= 1980)
valid <- valid %>% filter(as.integer(as.character(year)) >= 1980)

rmse_lst <- step_wise_loop(df = train %>% select(genre_xvar, content_rating, real_budget, year, 
                                                 total_oscars_actor, total_oscars_director,
                                                 imdb_score_log, real_budget_log,
                                                 director_facebook_likes_log, cast_total_facebook_likes_log),
                           starting_vars = genre_xvar, 
                           starting_formula = starting_formula)

# graph RMSE vs number of variables
fit_rmse <- tibble(nvar = 1:length(rmse_lst), 
                   rmse = rmse_lst)
ggplot(fit_rmse) + geom_line(aes(x = nvar, y = rmse))+ 
  scale_x_continuous(breaks = seq(1, length(rmse_lst), by = 1))
# after var 4, decreases too small or increase 

# model with extra 4 variables
mod_all <- lm(real_gross_log ~ Adventure + Action + Family + Mystery + 
                  Documentary + Drama + History + Romance + 
                  real_budget_log + imdb_score_log + year + content_rating, 
          data = train)

summary(mod_all)
rmse(mod_all, data = valid)

# number of observations
  # lost about 150 observations to missings
nobs(mod_all)
```

## New Residuals

Graph residuals of included and excluded variables: have we captured all of the relationships? 

```{r mod_all_resid}
# get log versions of variables since residuals are log: same scale 
train_all_resid <- train %>%
  add_residuals(mod_all, 'lresid') %>%
  mutate_at(vars('real_budget', 'director_facebook_likes', 'cast_total_facebook_likes', 
         'imdb_score'), funs(log = log10(.)))

# graph each against log residual: continuous
lapply(c('real_budget', 'director_facebook_likes', 'cast_total_facebook_likes', 
         'imdb_score'), function(var) {
  train_all_resid %>% 
    ggplot() + 
    geom_point(aes_string(str_c(var, '_log'), y = 'lresid'))
})

# categorical 
# can't log categorical variables 
lapply(c('content_rating', 'year', genre_xvar), function(var) {
  train_all_resid %>%
    filter(!is.na(!!rlang::sym(var))) %>%
    ggplot() + 
    geom_boxplot(aes_string(var, 'lresid'))
})

# qq plot of residuals
train_all_resid %>% ggplot() + 
  geom_qq(aes(sample = lresid))
```
## TO DO  

Week: 
* Some of the genre variables are now insigificant -> try full step wise from scratch. Some of these shouldn't be included? 
